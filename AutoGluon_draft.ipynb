{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Throughout this lesson, you've been trying different models on the same two datasets, wine and diabetes. Now, we're going to try our hand at accelerating this methodology by using AutoGluon. In this exercise, train two different AutonGluon models and see how they compare to previous iterations in exercise 1 and 2.\n\nYou're tasked with completing the following steps:\n1. Load in the wine dataset from scikit learn.\n2. For the wine dataset, create a train and test split, 80% train / 20% test.\n3. Create a AutoGluon Classifier model with these hyper parameters:\n    1. time_limit: 120\n    2. presets: best_quality\n4. Output the model table summary\n5. Evaluate the trained model on the test dataset\n6. Load the diabetes dataset from scikit learn\n7. For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n8. Create a AutoGluon Regression model with these hyper parameters:\n    1. eval_metric: r2\n    2. time_limit: 120\n    3. presets: best_quality\n9. Output the model table summary\n10. Evaluate the trained model on the test dataset",
      "metadata": {},
      "id": "d9520883-fb9c-42fd-8d73-d19e3a401c7f"
    },
    {
      "cell_type": "markdown",
      "source": "## Setup",
      "metadata": {},
      "id": "8b0ac658-af67-4355-a789-147a1a98b7cd"
    },
    {
      "cell_type": "markdown",
      "source": "### Open up Sagemaker Studio",
      "metadata": {},
      "id": "dc846de2-0e72-4935-a786-ae65df4f2948"
    },
    {
      "cell_type": "markdown",
      "source": "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`",
      "metadata": {},
      "id": "4a4cbe42-87c5-4671-87e4-507764ad0ed4"
    },
    {
      "cell_type": "code",
      "source": "# !pip install -U pip\n# !pip install -U setuptools wheel\n# !pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n# !pip install autogluon --no-cache-dir",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [],
      "id": "d158af04-dd1d-4e26-8e63-e81de4e6bbfc"
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn.metrics import r2_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom autogluon.tabular import TabularDataset, TabularPredictor",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'autogluon'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score, accuracy_score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularDataset, TabularPredictor\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'"
          ],
          "output_type": "error"
        }
      ],
      "id": "6dfefd6d-ed7f-46e3-a0c0-befda8d6aa23"
    },
    {
      "cell_type": "markdown",
      "source": "## AutoGluon Classifier",
      "metadata": {},
      "id": "66e6fd8c-df16-4109-a7a8-6c6ccb2cdf29"
    },
    {
      "cell_type": "code",
      "source": "# Load in the wine dataset\nwine = datasets.load_wine()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [],
      "id": "fc9c70a0-c311-4cf7-befb-92641f071326"
    },
    {
      "cell_type": "code",
      "source": "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\ndf = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n\n# Include the target as well\ndf['target'] = wine['target']",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [],
      "id": "2d674674-0c0f-4a2a-8d0a-c8b1fc4c11a0"
    },
    {
      "cell_type": "code",
      "source": "# Split your data with these ratios: train: 0.8 | test: 0.2\ndf_train, df_test = train_test_split(df, test_size = 0.2, random_state = 0)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [],
      "id": "75ee9c82-4e05-4952-8be9-7f823436d32b"
    },
    {
      "cell_type": "code",
      "source": "# How does the model perform on the training dataset and default model parameters?\n# Using the hyperparameters in the requirements, is there improvement?\n# Remember we use the test dataset to score the model\n# No need to explicitly say this is a classifier, autogluon will pick it up\npredictor = TabularPredictor(label = 'target').fit(train_data = df, time_limit = 120, presets=\"best_quality\")",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'TabularPredictor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# How does the model perform on the training dataset and default model parameters?\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using the hyperparameters in the requirements, is there improvement?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Remember we use the test dataset to score the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# No need to explicitly say this is a classifier, autogluon will pick it up\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m(label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(train_data \u001b[38;5;241m=\u001b[39m df, time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m, presets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_quality\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TabularPredictor' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "id": "7205ac08-20cd-48c5-a90e-44960f6d81f6"
    },
    {
      "cell_type": "code",
      "source": "# Output the fit summary of the training run\npredictor.fit_summary()",
      "metadata": {
        "tags": []
      },
      "execution_count": null,
      "outputs": [],
      "id": "46b15550-b62b-4a80-857e-12710eee9e73"
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the models performance on the test dataset\nperformance = predictor.evaluate(df)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "373d5630-84b5-4fbb-9b9a-08871ec4fe98"
    },
    {
      "cell_type": "markdown",
      "source": "## AutoGluon Regression",
      "metadata": {},
      "id": "8614c377-9f5b-4a2a-bc3c-0a049413b6e5"
    },
    {
      "cell_type": "code",
      "source": "# Load in the diabetes dataset\ndiabetes = datasets.load_diabetes()",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "6fe39b07-53b3-4576-b392-1a1df77b43f7"
    },
    {
      "cell_type": "code",
      "source": "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\ndfd = pd.DataFrame(diabetes['data'], columns = diabetes['feature_names'])\n\n# Include the target as well\ndfd['target'] = diabetes['target']",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "e36b9530-5bcd-40b4-a1f0-e6ad32bac145"
    },
    {
      "cell_type": "code",
      "source": "# Split your data with these ratios: train: 0.8 | test: 0.2\ndfd_train, dfd_test = train_test_split(dfd, test_size = 0.2, random_state = 0)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "85a9b895-00a5-48b9-951f-e36436255d5c"
    },
    {
      "cell_type": "code",
      "source": "# How does the model perform on the training dataset and default model parameters?\n# Using the hyperparameters in the requirements, is there improvement?\n# Remember we use the test dataset to score the model\n# No need to explicitly say this is a regression, autogluon will pick it up\npredictor = TabularPredictor(label = 'target').fit(\n    train_data = dfd, \n    eval_metric = 'r2',\n    time_limit = 120,\n    presets = 'best_quality'\n    )",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'TabularPredictor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# How does the model perform on the training dataset and default model parameters?\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using the hyperparameters in the requirements, is there improvement?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Remember we use the test dataset to score the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# No need to explicitly say this is a regression, autogluon will pick it up\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m(label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      6\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m dfd, \n\u001b[1;32m      7\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m,\n\u001b[1;32m      9\u001b[0m     presets \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_quality\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TabularPredictor' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "id": "1b0f9d06-9436-4a4e-988d-f0ad00b26e10"
    },
    {
      "cell_type": "code",
      "source": "# Output the fit summary of the training run\npredictor.fit_summary()",
      "metadata": {
        "tags": []
      },
      "execution_count": null,
      "outputs": [],
      "id": "1b09621b-9ce7-4889-bcf9-c9b8687438ef"
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the models performance on the test dataset\nperformance = predictor.evaluate(df)",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "98c39401-a8cb-4e6c-aabb-c318f384e423"
    }
  ]
}